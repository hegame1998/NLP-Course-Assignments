{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCysh0hY19VZwmjRl/j0CA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hegame1998/NLP-Course-Assignments/blob/main/NLP%20Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I will do this approach in this code:\n",
        "\n",
        "\n",
        "* **Loads two documents:** one to summarize, one as style reference.\n",
        "\n",
        "* **Estimates token length** using word count (proxy for 4000-token limit).\n",
        "\n",
        "* **Performs chunk-based summarization** using TextRank-style TF-IDF cosine similarity.\n",
        "\n",
        "* **If the summary is too large**, it recursively shrinks it.\n",
        "\n",
        "* **Saves the summaries.**\n",
        "\n",
        "* **Prints a query prompt** to generate a style-following summary."
      ],
      "metadata": {
        "id": "oEUtBIJj_XKr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Collection"
      ],
      "metadata": {
        "id": "-bYgasEGDHiu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is where I load my input and style reference documents.<br> Read two input text files (T1: style source, T2: text to summarize).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7LXniapmDbse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import nltk\n",
        "import numpy as np\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from collections import Counter\n",
        "\n",
        "from google.colab import files\n",
        "style_text, target_text = load_documents('your_style_filename.txt', 'your_target_filename.txt')\n",
        "\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "Q6dF7HNjEWI5",
        "outputId": "b700214e-5fe2-4ee5-ff66-210a4548c4e0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'load_documents' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-1621873928.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mstyle_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'your_style_filename.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'your_target_filename.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'load_documents' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Data Collection ===\n",
        "def load_documents(style_path, target_path):\n",
        "    with open(style_path, 'r', encoding='utf-8') as f:\n",
        "        style_text = f.read()\n",
        "    with open(target_path, 'r', encoding='utf-8') as f:\n",
        "        target_text = f.read()\n",
        "    return style_text, target_text"
      ],
      "metadata": {
        "id": "WV4CiV-sDHJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocessing"
      ],
      "metadata": {
        "id": "lrSiUDQRDSM2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clean and tokenize the text.\n",
        "\n",
        "* Tokenize T1 and T2.\n",
        "\n",
        "* Count token lengths.\n",
        "\n",
        "* Define target lengths proportionally."
      ],
      "metadata": {
        "id": "Rgrd9ocpDhRI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Preprocessing ===\n",
        "def preprocess(text):\n",
        "    nltk.download('punkt')\n",
        "    sentences = sent_tokenize(text)\n",
        "    words = word_tokenize(text)\n",
        "    return sentences, words\n",
        "\n",
        "def get_token_count(words):\n",
        "    return len(words)\n",
        "\n",
        "def split_into_chunks(sentences, max_tokens):\n",
        "    chunks = []\n",
        "    current_chunk = []\n",
        "    token_count = 0\n",
        "    for sent in sentences:\n",
        "        tokens = word_tokenize(sent)\n",
        "        if token_count + len(tokens) > max_tokens:\n",
        "            chunks.append(' '.join(current_chunk))\n",
        "            current_chunk = [sent]\n",
        "            token_count = len(tokens)\n",
        "        else:\n",
        "            current_chunk.append(sent)\n",
        "            token_count += len(tokens)\n",
        "    if current_chunk:\n",
        "        chunks.append(' '.join(current_chunk))\n",
        "    return chunks\n"
      ],
      "metadata": {
        "id": "IPoeqT2oDVjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Extraction"
      ],
      "metadata": {
        "id": "1xV4brfYDY3k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use TF-IDF and cosine similarity to rank sentences for summarization.\n",
        "\n",
        "* Extract stylistic features from T1 (sentence length, punctuation usage, common POS tags).\n",
        "\n",
        "* Optionally, compute average sentence length and POS tag distribution.\n"
      ],
      "metadata": {
        "id": "Zpf3mDt5Dkgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Feature Extraction ===\n",
        "def extract_style_features(text):\n",
        "    words = word_tokenize(text)\n",
        "    tagged = nltk.pos_tag(words)\n",
        "    pos_counts = Counter(tag for word, tag in tagged)\n",
        "    avg_sentence_length = sum(len(word_tokenize(s)) for s in sent_tokenize(text)) / len(sent_tokenize(text))\n",
        "    return {'pos_distribution': pos_counts, 'avg_sentence_length': avg_sentence_length}\n",
        "\n"
      ],
      "metadata": {
        "id": "ElxMj4FeDnJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Training (Extractive Summarizer + Style Bias)"
      ],
      "metadata": {
        "id": "_jhXgByhDsYu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Iteratively summarize large texts to fit the context window (e.g., 4000 tokens).\n",
        "\n",
        "* Weâ€™ll implement an extractive summarization method using scoring (TF-IDF or frequency-based).\n",
        "\n",
        "* No external model training is required.\n",
        "\n",
        "* For style adaptation, re-rank or rewrite based on stylistic features from T1."
      ],
      "metadata": {
        "id": "TyephVpGDvg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Model Training / Hierarchical Summarization ===\n",
        "def score_sentences(sentences, style_features):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    scores = {}\n",
        "    for sent in sentences:\n",
        "        words = word_tokenize(sent.lower())\n",
        "        words = [w for w in words if w not in stop_words and w not in string.punctuation]\n",
        "        score = sum(1 for w in words)  # basic frequency count\n",
        "        if abs(len(words) - style_features['avg_sentence_length']) < 5:\n",
        "            score += 2  # stylistic bonus\n",
        "        scores[sent] = score\n",
        "    return scores\n",
        "\n",
        "def summarize_chunk(chunk, style_features, target_sentences=5):\n",
        "    sentences = sent_tokenize(chunk)\n",
        "    scores = score_sentences(sentences, style_features)\n",
        "    ranked = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    selected = [sent for sent, score in ranked[:target_sentences]]\n",
        "    return ' '.join(selected)\n",
        "\n"
      ],
      "metadata": {
        "id": "pH9dTZGDDuma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluation"
      ],
      "metadata": {
        "id": "AYddWpftD1LG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output and save summaries, simulate a style-following prompt.\n",
        "\n",
        "* Manual or ROUGE-based metrics (if available).\n",
        "\n",
        "* Summary length check vs context window."
      ],
      "metadata": {
        "id": "v_NqhIKzD3K9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Evaluation ===\n",
        "def check_summary_length(summary, token_limit=4000):\n",
        "    words = word_tokenize(summary)\n",
        "    return len(words) <= token_limit"
      ],
      "metadata": {
        "id": "tMBYUPYPD6pb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Main Function"
      ],
      "metadata": {
        "id": "y2WTpIhXD-le"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To tie everything together.\n",
        "\n",
        "* Orchestrates all components.\n",
        "\n",
        "* Repeats summarization until the result fits within the token limit.\n"
      ],
      "metadata": {
        "id": "wqOZD7IKEBKT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Entry Point ===\n",
        "def hierarchical_summarize(style_text, target_text, token_limit=4000):\n",
        "    _, style_words = preprocess(style_text)\n",
        "    style_features = extract_style_features(style_text)\n",
        "\n",
        "    target_sentences, target_words = preprocess(target_text)\n",
        "    if len(target_words) <= token_limit:\n",
        "        return summarize_chunk(target_text, style_features)\n",
        "\n",
        "    chunks = split_into_chunks(target_sentences, token_limit)\n",
        "    summaries = [summarize_chunk(chunk, style_features) for chunk in chunks]\n",
        "\n",
        "    final_summary = ' '.join(summaries)\n",
        "\n",
        "    # Recursively summarize until within limit\n",
        "    while not check_summary_length(final_summary, token_limit):\n",
        "        final_summary = summarize_chunk(final_summary, style_features)\n",
        "\n",
        "    return final_summary\n",
        "\n"
      ],
      "metadata": {
        "id": "HhacIpOsEC1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Usage Example"
      ],
      "metadata": {
        "id": "BPpKgm2zyLwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    style_text, target_text = load_documents('style.txt', 'to_summarize.txt')\n",
        "    final_summary = hierarchical_summarize(style_text, target_text)\n",
        "\n",
        "    with open(\"summary.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(final_summary)\n"
      ],
      "metadata": {
        "id": "pKoSFLx4yKGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* This is a basic extractive summarization method with stylistic guidance.\n",
        "\n",
        "* You can extend it with nltk.Text for deeper stylistic mimicry or switch to using BERT embeddings (if allowed).\n",
        "\n",
        "* If you want to go further, I can help implement a transformer-based abstractive model in Hugging Face and control style via prompt engineering."
      ],
      "metadata": {
        "id": "1BRIhMJsyhRg"
      }
    }
  ]
}